# Eye-commands

## Can we build a user interface for individuals with severely-limited mobility using only an ordinary camera and machine learning?

### This is a project started by Lucas Henrique, Daniel Kashkett, and Giovanbattista Amato for a UK based non-profit called AceCentre. AceCentre works with individuals with difficulties to communicate. The Eye-Commander is designed as an open-source solution to eye-tracking that will work without the need for a fancy camera or expensive software. 

# Usage
### To be able to run the computer vision approach on this repo just run the example.py script and do a quick calibration as instructed on the screen, for a better performance try to center your face on frame and always face fowards towards the camera, also try to have even lighting on your face and avoid any light from the sides.

### To run the deep learning approach just run the example_deep.py script. 
